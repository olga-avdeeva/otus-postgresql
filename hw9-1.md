### Развертывание CocroachDb в GKE 

* создала кластер (по-умолчанию из 3 нод)  

      gcloud container clusters create cockroachdb --machine-type n1-standard-2 --zone us-central1-a
      
* создала роли RBAC, которые нужны CockroachDB для запуска на GKE  

      kubectl create clusterrolebinding $USER-cluster-admin-binding --clusterrole=cluster-admin --user=olga.i.avdeeva@gmail.com
      
* Установила Helm, добавила в него репозиторий cockroachdb  

      helm repo add cockroachdb https://charts.cockroachdb.com/
      
* Создала свою модификацию параметров для сценария развертывания, в которой ограничила память 2Gi и кэш 1Gi.  Установила пакет CockroachDB используя свои параметры.  

      helm install my-release --values my-values.yaml cockroachdb/cockroachdb
      
      kubectl get all
      
      NAME                                    READY   STATUS      RESTARTS   AGE
      pod/cockroachdb                         1/1     Running     0          22h
      pod/my-release-cockroachdb-0            1/1     Running     13         24h
      pod/my-release-cockroachdb-1            1/1     Running     15         24h
      pod/my-release-cockroachdb-2            1/1     Running     13         24h
      pod/my-release-cockroachdb-init-mxrjw   0/1     Completed   0          24h
      
      NAME                                    TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)              AGE
      service/kubernetes                      ClusterIP   10.107.240.1     <none>        443/TCP              28h
      service/my-release-cockroachdb          ClusterIP   None             <none>        26257/TCP,8080/TCP   24h
      service/my-release-cockroachdb-public   ClusterIP   10.107.247.137   <none>        26257/TCP,8080/TCP   24h
      
      NAME                                      READY   AGE
      statefulset.apps/my-release-cockroachdb   3/3     24h
      
      NAME                                    COMPLETIONS   DURATION   AGE
      job.batch/my-release-cockroachdb-init   1/1           23s        24h
      
* Сделала проброс порта, для подключения к кластеру напрямую. 

      kubectl port-forward my-release-cockroachdb-0 26257
      
* Подключилась к кластеру. Создала БД demo, создала таблицу для данных chicago taxi, загрузила в таблицу данные 40 файлов (около 10GB).  

      psql -h localhost -p 26257 -U root
      
      import into taxi_trips_new (unique_key,taxi_id,trip_start_timestamp,trip_end_timestamp,trip_seconds,trip_miles,pickup_census_tract,dropoff_census_tract,pickup_community_area,dropoff_community_area,
      fare,tips,tolls,extras,trip_total,payment_type,company,pickup_latitude,pickup_longitude,pickup_location,dropoff_latitude,dropoff_longitude,dropoff_location) 
      CSV DATA (
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000000',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000001',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000002',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000003',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000004',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000005',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000006',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000007',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000008',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000009',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000010',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000011',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000012',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000013',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000014',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000015',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000016',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000017',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000018',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000019',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000020',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000021',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000022',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000023',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000024',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000025',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000026',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000027',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000028',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000029',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000030',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000031',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000032',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000033',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000034',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000035',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000036',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000037',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000038',
      'gs://otus-big-data/taxi/chicago_taxi.csv.000000000039'
      ) WITH DELIMITER = ',', nullif = '', SKIP = '1';
      
* выполнила запрос, подсчитывающий количество строк в таблице  

      demo=# \timing
      Timing is on.
      demo=# select count(*) from taxi_trips_new;
        count   
      ----------
       31682843
      (1 row)
      
      Time: 78059.446 ms (01:18.059)
      
Запрос выполнялся чуть больше минуты. Для сравнения, на одном инстансе PostgreSql подсчет количества строк на объеме данных 25Gb = 67267596 строк (ДЗ 6) выполнялся 573357 ms = 9 минут 33 секунды


      
